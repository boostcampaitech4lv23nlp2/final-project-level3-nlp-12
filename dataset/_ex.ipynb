{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('/opt/ml/input/code/final-project-level3-nlp-12/riffusion')\n",
    "import os\n",
    "from typing import Iterator, TextIO\n",
    "from transformers import pipeline\n",
    "from _interpolation import Riffusion_interpolation\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "[00:00.000 --> 00:06.880]  I heard that Woo-King taught Lee Kyung-kyu, a 42-year-old entertainer, how to broadcast.\n",
    "[00:06.880 --> 00:11.240]  Of course, I'm sure you've done a lot of studio programs like this.\n",
    "[00:11.240 --> 00:16.120]  In the Internet live broadcast, the real-time communication is a little different.\n",
    "[00:16.120 --> 00:18.040]  Communication is really important.\n",
    "[00:18.040 --> 00:20.200]  He's always looking at the camera.\n",
    "[00:20.200 --> 00:23.760]  Actually, in the Internet live broadcast, you have to look at this more than this.\n",
    "[00:23.760 --> 00:26.120]  That's right. The comments are hard.\n",
    "[00:26.120 --> 00:30.720]  And in the live broadcast, there's a donation system.\n",
    "[00:30.720 --> 00:32.920]  That's a no-no.\n",
    "[00:32.920 --> 00:35.520]  You have to listen to it no matter what.\n",
    "[00:35.520 --> 00:36.920]  Oh, if you listen to the sponsorship, you have to do this.\n",
    "[00:36.920 --> 00:39.080]  Thank you for your donation.\n",
    "[00:39.080 --> 00:40.640]  You don't have to do it regardless of the program.\n",
    "[00:40.640 --> 00:43.160]  Oh, I'll leave it alone.\n",
    "[00:43.160 --> 00:45.040]  It's good to get a lot of pay.\n",
    "[00:45.040 --> 00:47.360]  That's the same thing.\n",
    "[00:47.360 --> 00:51.000]  There are real-time comments, so there's a tip for reading them.\n",
    "[00:51.000 --> 00:52.280]  There's going to be a lot of comments.\n",
    "[00:52.280 --> 00:53.200]  It's been a while.\n",
    "[00:53.200 --> 00:56.160]  Almost 4,000 to 5,000 people go and watch it.\n",
    "[00:56.160 --> 00:57.080]  How do I read this?\n",
    "[00:57.080 --> 01:01.400]  Then you can read people like Kim Gu-ran.\n",
    "[01:01.400 --> 01:06.320]  Like Kim Gu-ran, there are people who always talk in the 12th group in the comments.\n",
    "[01:06.320 --> 01:09.680]  I don't leave comments.\n",
    "[01:09.680 --> 01:11.680]  That's the way you talk.\n",
    "[01:11.680 --> 01:13.200]  I don't leave comments on purpose.\n",
    "[01:13.200 --> 01:15.200]  I don't leave comments on purpose, everyone.\n",
    "[01:15.200 --> 01:16.200]  There are people who scratch it.\n",
    "[01:16.200 --> 01:17.200]  I scratch it for fun.\n",
    "[01:17.200 --> 01:19.200]  Then it becomes a tiki-taka.\n",
    "[01:19.200 --> 01:22.200]  If you focus on those people, you can have fun on the air.\n",
    "[01:22.200 --> 01:24.200]  But it went by so fast.\n",
    "[01:24.200 --> 01:25.200]  How do you catch it?\n",
    "[01:25.200 --> 01:26.200]  It's good for your eyesight.\n",
    "[01:26.200 --> 01:27.200]  That's right.\n",
    "[01:27.200 --> 01:30.200]  No, we're just talking about eye sight.\n",
    "[01:30.200 --> 01:34.200]  I'm the only one who sees it on the screen.\n",
    "[01:34.200 --> 01:35.200]  It's fast.\n",
    "[01:35.200 --> 01:36.200]  It's fast.\n",
    "[01:36.200 --> 01:39.200]  The problem is that Won is here.\n",
    "[01:39.200 --> 01:45.200]  I can't see it, so I keep looking at it like this.\n",
    "[01:45.200 --> 01:50.200]  Okay, there's a special skill that makes you excited when you do that.\n",
    "[01:50.200 --> 01:51.200]  There should be one.\n",
    "[01:51.200 --> 01:52.200]  This, this.\n",
    "[01:52.200 --> 01:53.200]  That's right.\n",
    "[01:53.200 --> 01:54.200]  Actually, I didn't make it now.\n",
    "[01:54.200 --> 01:58.200]  What's sitting here right now is my knee dance.\n",
    "[01:58.200 --> 01:59.200]  This is a real signature dance.\n",
    "[01:59.200 --> 02:00.200]  This is what you're looking at.\n",
    "[02:00.200 --> 02:03.200]  Didn't you say you're going to pay for the donation?\n",
    "[02:03.200 --> 02:04.200]  Depending on the donation amount.\n",
    "[02:04.200 --> 02:05.200]  Yes.\n",
    "[02:05.200 --> 02:06.200]  This is the highest price.\n",
    "[02:06.200 --> 02:07.200]  The highest price.\n",
    "[02:07.200 --> 02:10.200]  Let's take a look.\n",
    "[02:10.200 --> 02:13.200]  I can't believe you're looking at this.\n",
    "[02:13.200 --> 02:23.200]  Let's go with 70 million won.\n",
    "[02:27.200 --> 02:28.200]  It's 1 million won.\n",
    "[02:28.200 --> 02:29.200]  It's 1 million won.\n",
    "[02:29.200 --> 02:30.200]  It's 1 million won.\n",
    "[02:30.200 --> 02:31.200]  To the side.\n",
    "[02:31.200 --> 02:31.200]  To the side.\n",
    "[02:31.200 --> 02:41.200]  To the side.\n",
    "[02:41.200 --> 02:46.200]  Wow, how does this work?\n",
    "[02:46.200 --> 02:48.200]  I've never seen this before.\n",
    "[02:48.200 --> 03:13.200]  It's an honor. It's an honor.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 6], [6, 11], [11, 16], [16, 18], [18, 20], [20, 23], [23, 26], [26, 30], [30, 32], [32, 35], [35, 36], [36, 39], [39, 40], [40, 43], [43, 45], [45, 47], [47, 51], [51, 52], [52, 53], [53, 56], [56, 57], [57, 61], [61, 66], [66, 69], [69, 71], [71, 73], [73, 75], [75, 76], [76, 77], [77, 79], [79, 82], [82, 84], [84, 85], [85, 86], [86, 87], [87, 90], [90, 94], [94, 95], [95, 96], [96, 99], [99, 105], [105, 110], [110, 111], [111, 112], [112, 113], [113, 114], [114, 118], [118, 119], [119, 120], [120, 123], [123, 124], [124, 125], [125, 126], [126, 127], [127, 130], [130, 133], [133, 143], [147, 148], [148, 149], [149, 150], [150, 151], [151, 151], [151, 161], [161, 166], [166, 168], [168, 193]]\n"
     ]
    }
   ],
   "source": [
    "times = re.findall(r'\\[.+\\]', text)\n",
    "result = []\n",
    "for t in times:\n",
    "            start, end = t.split('-->')\n",
    "            start, end = int(start[1:].strip()[:-4].split(':')[0])*60+int(start[1:].strip()[:-4].split(':')[1]), int(end[1:].strip()[:-4].split(':')[0])*60+int(end[1:].strip()[:-5].split(':')[1])\n",
    "            result.append([start, end])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.sub(r'\\[.+\\]', '', text).split('\\n')\n",
    "text = [t.strip() for t in text if t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "sentiment = pipeline(\"sentiment-analysis\", model='cardiffnlp/twitter-roberta-base-sentiment-latest', tokenizer='cardiffnlp/twitter-roberta-base-sentiment-latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 142, but you input_length is only 67. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=33)\n",
      "Your max_length is set to 142, but you input_length is only 55. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=27)\n",
      "Your max_length is set to 142, but you input_length is only 25. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n",
      "Your max_length is set to 142, but you input_length is only 31. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n",
      "Your max_length is set to 142, but you input_length is only 22. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n",
      "Your max_length is set to 142, but you input_length is only 55. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=27)\n",
      "Your max_length is set to 142, but you input_length is only 64. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=32)\n",
      "Your max_length is set to 142, but you input_length is only 12. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'summary_text': \"In the Internet live broadcast, the real-time communication is a little different. Of course, I'm sure you've done a lot of studio programs like this. He's always looking at the camera.Actually, in the Internet Live broadcast, you have to look at this more.\"}],\n",
       " [{'summary_text': \"You have to listen to it no matter what. That's right. The comments are hard. And in the live broadcast, there's a donation system.That's a no-no. Oh, if you listen to the sponsorship, you have to do this. That is right.\"}],\n",
       " [{'summary_text': \"There are real-time comments, so there's a tip for reading them. Almost 4,000 to 5,000 people go and watch it. You don't have to do it regardless of the program. It's good to get a lot of pay. That's the same thing.\"}],\n",
       " [{'summary_text': \"I can't see it, so I keep looking at it like this. The problem is that Won is here. I can't seem to see it. I'm looking for it, but it's not there. I don't know what it is. I just want to know what's going on.\"}],\n",
       " [{'summary_text': \"This, this. Okay, there's a special skill that makes you excited when you do that. There should be one. That's right. This is it. This, this is what it's all about. This should be it. It's the only thing that gets you excited.\"}],\n",
       " [{'summary_text': \"What's sitting here right now is my knee dance. Actually, I didn't make it now. What's sitting there right now are my knee dances. What is sitting here? My knee danced. What was that? I don't know. I'm doing the knee dance right now.\"}],\n",
       " [{'summary_text': \"This is a real signature dance. Depending on the donation amount. This is the highest price. Let's take a look.This is what you're looking at.Didn't you say you're going to pay for the donation?Depending on the donations amount.Yes.\"}],\n",
       " [{'summary_text': \"Let's go with 70 million won.It's 1 millionwon.To the side. I can't believe you're looking at this. It's 1million won. To the side of the screen. It looks like a picture of a person's face. It appears to be a person.\"}],\n",
       " [{'summary_text': 'CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery. Please submit your best shots of the U.S. for next week. Visit CNN.com/Travel each week for a new gallery of snapshots. Visit http://www.dailymail.co.uk/travel/features/travelling-with-the-world-in-pictures-travellers-tune-in.'}]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments = []\n",
    "for t in text:\n",
    "    sentiments.append(sentiment(t))\n",
    "flag = None\n",
    "contents = []\n",
    "for x,y in zip(text, sentiments):\n",
    "    if flag == None:\n",
    "        if y[0]['label'] == 'positive':\n",
    "            flag = True\n",
    "            contents.append([x])\n",
    "        elif y[0]['label'] == 'negative':\n",
    "            flag = False\n",
    "            contents.append([x])\n",
    "    else:\n",
    "        if flag == False:\n",
    "            if y[0]['label'] == 'positive':\n",
    "                flag = True\n",
    "                contents.append([x])\n",
    "            else:\n",
    "                contents[-1] += [x]\n",
    "        else:\n",
    "            if y[0]['label'] == 'negative':\n",
    "                flag = False\n",
    "                contents.append([x])\n",
    "            else:\n",
    "                contents[-1] += [x]\n",
    "contents = list(map(''.join, contents))\n",
    "# summarized = []\n",
    "# for x in contents:\n",
    "#     summarized.append(summarizer(x))\n",
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('/opt/ml/input/code/final-project-level3-nlp-12/riffusion')\n",
    "import os\n",
    "from typing import Iterator, TextIO\n",
    "from transformers import pipeline\n",
    "from interpolation import Riffusion_interpolation\n",
    "import re\n",
    "\n",
    "class SentimentModel():\n",
    "    def __init__(self, text):\n",
    "        self.text = self.preprocessing(text)\n",
    "        self.time = self.gettime(text)\n",
    "        self.summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "        #self.sentiment = pipeline(\"sentiment-analysis\", model='cardiffnlp/twitter-roberta-base-sentiment-latest', tokenizer='cardiffnlp/twitter-roberta-base-sentiment-latest')\n",
    "        self.classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True)\n",
    "    \n",
    "    def preprocessing(self, text):\n",
    "        text = re.sub(r'\\[.+\\]', '', text).split('\\n')\n",
    "        text = [t.strip() for t in text if t]\n",
    "        return text\n",
    "    \n",
    "    def gettime(self, text):\n",
    "        times = re.findall(r'\\[.+\\]', text)\n",
    "        result = []\n",
    "        for t in times:\n",
    "            start, end = t.split('-->')\n",
    "            start, end = int(start[1:].strip()[:-4].split(':')[0])*60+int(start[1:].strip()[:-4].split(':')[1]), int(end[1:].strip()[:-4].split(':')[0])*60+int(end[1:].strip()[:-5].split(':')[1])\n",
    "            result.append([start, end])\n",
    "        return result\n",
    "    # def run(self):\n",
    "    #     sentiments = []\n",
    "    #     text = self.text\n",
    "    #     for t in text:\n",
    "    #         sentiments.append(self.sentiment(t))\n",
    "    #     flag = None\n",
    "    #     contents = []\n",
    "    #     for x,y in zip(text, sentiments):\n",
    "    #         if flag == None:\n",
    "    #             if y[0]['label'] == 'positive':\n",
    "    #                 flag = True\n",
    "    #                 contents.append([x])\n",
    "    #             elif y[0]['label'] == 'negative':\n",
    "    #                 flag = False\n",
    "    #                 contents.append([x])\n",
    "    #         else:\n",
    "    #             if flag == False:\n",
    "    #                 if y[0]['label'] == 'positive':\n",
    "    #                     flag = True\n",
    "    #                     contents.append([x])\n",
    "    #                 else:\n",
    "    #                     contents[-1] += [x]\n",
    "    #             else:\n",
    "    #                 if y[0]['label'] == 'negative':\n",
    "    #                     flag = False\n",
    "    #                     contents.append([x])\n",
    "    #                 else:\n",
    "    #                     contents[-1] += [x]\n",
    "    #     contents = list(map(''.join, contents))\n",
    "    #     summarized = []\n",
    "    #     for x in contents:\n",
    "    #         summarized.append(self.summarizer(x))\n",
    "    #     return summarized\n",
    "    def run(self):\n",
    "        sentiments = []\n",
    "        text = self.text\n",
    "        for t in text:\n",
    "            result = self.classifier(t)[0]\n",
    "            result.sort(key = lambda x: x['score'], reverse = True)\n",
    "            sentiments.append(result[0]['label'])\n",
    "        sentiment = None\n",
    "        contents = []\n",
    "        threshold = 2\n",
    "        start = 0\n",
    "        for x, y in zip(sentiments, self.time):\n",
    "            if sentiment == None:\n",
    "                if x != 'neutral':\n",
    "                    sentiment = x\n",
    "                    start = y[0]\n",
    "            else:\n",
    "                if x != sentiment and x != 'neutral':\n",
    "                    if y[0] - start >= threshold:\n",
    "                        contents.append([start, y[0], sentiment])\n",
    "                    sentiment = x\n",
    "                    start = y[0]\n",
    "        return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[36, 56, 'joy'], [56, 79, 'surprise'], [79, 82, 'joy'], [82, 168, 'surprise']]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = SentimentModel(text)\n",
    "summarized_content = sen.run()\n",
    "summarized_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/whisper/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True)\n",
    "result = classifier(\"I love this!\")[0]\n",
    "result.sort(key = lambda x: x['score'], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gettime(text):\n",
    "        times = re.findall(r'\\[.+\\]', text)\n",
    "        result = []\n",
    "        for t in times:\n",
    "            start, end = t.split('-->')\n",
    "            start, end = start[1:].strip()[:-4], end[:-1].strip()[:-4]\n",
    "            result.append([start, end])\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['00:00', '00:06'],\n",
       " ['00:06', '00:11'],\n",
       " ['00:11', '00:16'],\n",
       " ['00:16', '00:18'],\n",
       " ['00:18', '00:20'],\n",
       " ['00:20', '00:23'],\n",
       " ['00:23', '00:26'],\n",
       " ['00:26', '00:30'],\n",
       " ['00:30', '00:32'],\n",
       " ['00:32', '00:35'],\n",
       " ['00:35', '00:36'],\n",
       " ['00:36', '00:39'],\n",
       " ['00:39', '00:40'],\n",
       " ['00:40', '00:43'],\n",
       " ['00:43', '00:45'],\n",
       " ['00:45', '00:47'],\n",
       " ['00:47', '00:51'],\n",
       " ['00:51', '00:52'],\n",
       " ['00:52', '00:53'],\n",
       " ['00:53', '00:56'],\n",
       " ['00:56', '00:57'],\n",
       " ['00:57', '01:01'],\n",
       " ['01:01', '01:06'],\n",
       " ['01:06', '01:09'],\n",
       " ['01:09', '01:11'],\n",
       " ['01:11', '01:13'],\n",
       " ['01:13', '01:15'],\n",
       " ['01:15', '01:16'],\n",
       " ['01:16', '01:17'],\n",
       " ['01:17', '01:19'],\n",
       " ['01:19', '01:22'],\n",
       " ['01:22', '01:24'],\n",
       " ['01:24', '01:25'],\n",
       " ['01:25', '01:26'],\n",
       " ['01:26', '01:27'],\n",
       " ['01:27', '01:30'],\n",
       " ['01:30', '01:34'],\n",
       " ['01:34', '01:35'],\n",
       " ['01:35', '01:36'],\n",
       " ['01:36', '01:39'],\n",
       " ['01:39', '01:45'],\n",
       " ['01:45', '01:50'],\n",
       " ['01:50', '01:51'],\n",
       " ['01:51', '01:52'],\n",
       " ['01:52', '01:53'],\n",
       " ['01:53', '01:54'],\n",
       " ['01:54', '01:58'],\n",
       " ['01:58', '01:59'],\n",
       " ['01:59', '02:00'],\n",
       " ['02:00', '02:03'],\n",
       " ['02:03', '02:04'],\n",
       " ['02:04', '02:05'],\n",
       " ['02:05', '02:06'],\n",
       " ['02:06', '02:07'],\n",
       " ['02:07', '02:10'],\n",
       " ['02:10', '02:13'],\n",
       " ['02:13', '02:23'],\n",
       " ['02:27', '02:28'],\n",
       " ['02:28', '02:29'],\n",
       " ['02:29', '02:30'],\n",
       " ['02:30', '02:31'],\n",
       " ['02:31', '02:31'],\n",
       " ['02:31', '02:41'],\n",
       " ['02:41', '02:46'],\n",
       " ['02:46', '02:48'],\n",
       " ['02:48', '03:13']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = gettime(text)\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6\n",
      "6 11\n",
      "11 16\n",
      "16 18\n",
      "18 20\n",
      "20 23\n",
      "23 26\n",
      "26 30\n",
      "30 32\n",
      "32 35\n",
      "35 36\n",
      "36 39\n",
      "39 40\n",
      "40 43\n",
      "43 45\n",
      "45 47\n",
      "47 51\n",
      "51 52\n",
      "52 53\n",
      "53 56\n",
      "56 57\n",
      "57 61\n",
      "61 66\n",
      "66 69\n",
      "69 71\n",
      "71 73\n",
      "73 75\n",
      "75 76\n",
      "76 77\n",
      "77 79\n",
      "79 82\n",
      "82 84\n",
      "84 85\n",
      "85 86\n",
      "86 87\n",
      "87 90\n",
      "90 94\n",
      "94 95\n",
      "95 96\n",
      "96 99\n",
      "99 105\n",
      "105 110\n",
      "110 111\n",
      "111 112\n",
      "112 113\n",
      "113 114\n",
      "114 118\n",
      "118 119\n",
      "119 120\n",
      "120 123\n",
      "123 124\n",
      "124 125\n",
      "125 126\n",
      "126 127\n",
      "127 130\n",
      "130 133\n",
      "133 143\n",
      "147 148\n",
      "148 149\n",
      "149 150\n",
      "150 151\n",
      "151 151\n",
      "151 161\n",
      "161 166\n",
      "166 168\n",
      "168 193\n"
     ]
    }
   ],
   "source": [
    "times = re.findall(r'\\[.+\\]', text)\n",
    "timeline = []\n",
    "for t in times:\n",
    "    start, end = t.split('-->')\n",
    "    start, end = int(start[1:].strip()[:-4].split(':')[0])*60+int(start[1:].strip()[:-4].split(':')[1]), int(end[1:].strip()[:-4].split(':')[0])*60+int(end[1:].strip()[:-5].split(':')[1])\n",
    "    timeline.append([start, end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentModel():\n",
    "    def __init__(self, text, timeline):\n",
    "        self.time = timeline\n",
    "        self.text = self.preprocessing(text)\n",
    "        self.summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "        self.classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True)\n",
    "    \n",
    "    def preprocessing(self, text):\n",
    "        text = re.sub(r'\\[.+\\]', '', text).split('\\n')\n",
    "        text = [t.strip() for t in text if t]\n",
    "        return text\n",
    "    \n",
    "    def run(self):\n",
    "        sentiments = []\n",
    "        text = self.text\n",
    "        for t in text:\n",
    "            result = self.classifier(t)[0]\n",
    "            result.sort(key = lambda x: x['score'], reverse = True)\n",
    "            sentiments.append(result[0]['label'])\n",
    "        sentiment = None\n",
    "        contents = []\n",
    "        min = 5\n",
    "        max = 20\n",
    "        start = 0\n",
    "        for x, y in zip(sentiments, self.time):\n",
    "            if sentiment == None:\n",
    "                if x != 'neutral':\n",
    "                    contents.append([start, int(y[0]), None])\n",
    "                    sentiment = x\n",
    "                    start = y[0]\n",
    "            else:\n",
    "                if x != sentiment and x != 'neutral':\n",
    "                    if int(y[0]) - start > min and int(y[0]) - start < max:\n",
    "                        contents.append([start, int(y[0]), sentiment])\n",
    "                    else:\n",
    "                        contents.append([start, int(y[0]), None])\n",
    "                    sentiment = x\n",
    "                    start = int(y[0])\n",
    "        # contents = [[3, 5, 'angry']] -> [3, [3, 5, 'angry'], 32, [37, 42, 'surprise']]\n",
    "        return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = SentimentModel(, )\n",
    "result = sent.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d92da0a1b2a9422f3c47c40724438aa15fd669204e554153def5387194ea7e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
