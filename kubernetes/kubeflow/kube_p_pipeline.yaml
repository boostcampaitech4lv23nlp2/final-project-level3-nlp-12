apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: test-pipeline-
  annotations: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.18, pipelines.kubeflow.org/pipeline_compilation_time: '2023-01-28T16:07:06.147734',
    pipelines.kubeflow.org/pipeline_spec: '{"name": "test_pipeline"}'}
  labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.18}
spec:
  entrypoint: test-pipeline
  templates:
  - name: first-stage
    container:
      args: ['----output-paths', /tmp/outputs/Output/data]
      command:
      - sh
      - -c
      - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
        'paramiko==3.0.0' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install
        --quiet --no-warn-script-location 'paramiko==3.0.0' --user) && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def first_stage():
            import paramiko
            ssh = paramiko.SSHClient()
            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
            ssh.connect('101.101.209.53', username='root', port='2235', key_filename='/var/data/jd_key',password='1234')

            stdin, stdout, stderr = ssh.exec_command(f'cd /opt/ml/final/model && conda activate JD && python stt_sent_test.py')
            sentiment_string = stdout.readline().strip()
            stdin.close()
            ssh.close()

            return sentiment_string

        def _serialize_str(str_value: str) -> str:
            if not isinstance(str_value, str):
                raise TypeError('Value "{}" has type "{}" instead of str.'.format(
                    str(str_value), str(type(str_value))))
            return str_value

        import argparse
        _parser = argparse.ArgumentParser(prog='First stage', description='')
        _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
        _parsed_args = vars(_parser.parse_args())
        _output_files = _parsed_args.pop("_output_paths", [])

        _outputs = first_stage(**_parsed_args)

        _outputs = [_outputs]

        _output_serializers = [
            _serialize_str,

        ]

        import os
        for idx, output_file in enumerate(_output_files):
            try:
                os.makedirs(os.path.dirname(output_file))
            except OSError:
                pass
            with open(output_file, 'w') as f:
                f.write(_output_serializers[idx](_outputs[idx]))
      image: python:3.7
      volumeMounts:
      - {mountPath: var/data, name: pipeline}
    outputs:
      parameters:
      - name: first-stage-Output
        valueFrom: {path: /tmp/outputs/Output/data}
      artifacts:
      - {name: first-stage-Output, path: /tmp/outputs/Output/data}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.18
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": ["----output-paths", {"outputPath": "Output"}], "command": ["sh",
          "-c", "(PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
          ''paramiko==3.0.0'' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install
          --quiet --no-warn-script-location ''paramiko==3.0.0'' --user) && \"$0\"
          \"$@\"", "sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\" > \"$program_path\"\npython3
          -u \"$program_path\" \"$@\"\n", "def first_stage():\n    import paramiko\n    ssh
          = paramiko.SSHClient()\n    ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n    ssh.connect(''101.101.209.53'',
          username=''root'', port=''2235'', key_filename=''/var/data/jd_key'',password=''1234'')\n\n    stdin,
          stdout, stderr = ssh.exec_command(f''cd /opt/ml/final/model && conda activate
          JD && python stt_sent_test.py'')\n    sentiment_string = stdout.readline().strip()\n    stdin.close()\n    ssh.close()\n\n    return
          sentiment_string\n\ndef _serialize_str(str_value: str) -> str:\n    if not
          isinstance(str_value, str):\n        raise TypeError(''Value \"{}\" has
          type \"{}\" instead of str.''.format(\n            str(str_value), str(type(str_value))))\n    return
          str_value\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''First
          stage'', description='''')\n_parser.add_argument(\"----output-paths\", dest=\"_output_paths\",
          type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files
          = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = first_stage(**_parsed_args)\n\n_outputs
          = [_outputs]\n\n_output_serializers = [\n    _serialize_str,\n\n]\n\nimport
          os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except
          OSError:\n        pass\n    with open(output_file, ''w'') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"],
          "image": "python:3.7"}}, "name": "First stage", "outputs": [{"name": "Output",
          "type": "String"}]}', pipelines.kubeflow.org/component_ref: '{}'}
    volumes:
    - name: pipeline
      persistentVolumeClaim: {claimName: kfpvc}
  - name: for-loop-2
    parallelism: 0
    inputs:
      parameters:
      - {name: first-stage-Output}
      - {name: loop-item-param-1-subvar-conda}
      - {name: loop-item-param-1-subvar-ip}
      - {name: loop-item-param-1-subvar-key}
      - {name: loop-item-param-1-subvar-port}
      - {name: loop-item-param-1-subvar-pw}
    dag:
      tasks:
      - name: second-stage
        template: second-stage
        arguments:
          parameters:
          - {name: first-stage-Output, value: '{{inputs.parameters.first-stage-Output}}'}
          - {name: loop-item-param-1-subvar-conda, value: '{{inputs.parameters.loop-item-param-1-subvar-conda}}'}
          - {name: loop-item-param-1-subvar-ip, value: '{{inputs.parameters.loop-item-param-1-subvar-ip}}'}
          - {name: loop-item-param-1-subvar-key, value: '{{inputs.parameters.loop-item-param-1-subvar-key}}'}
          - {name: loop-item-param-1-subvar-port, value: '{{inputs.parameters.loop-item-param-1-subvar-port}}'}
          - {name: loop-item-param-1-subvar-pw, value: '{{inputs.parameters.loop-item-param-1-subvar-pw}}'}
  - name: second-stage
    container:
      args: [--sentiment-string, '{{inputs.parameters.first-stage-Output}}', --ip,
        '{{inputs.parameters.loop-item-param-1-subvar-ip}}', --port, '{{inputs.parameters.loop-item-param-1-subvar-port}}',
        --key, '{{inputs.parameters.loop-item-param-1-subvar-key}}', --pw, '{{inputs.parameters.loop-item-param-1-subvar-pw}}',
        --conda, '{{inputs.parameters.loop-item-param-1-subvar-conda}}', '----output-paths',
        /tmp/outputs/Output/data]
      command:
      - sh
      - -c
      - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
        'paramiko==3.0.0' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install
        --quiet --no-warn-script-location 'paramiko==3.0.0' --user) && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def second_stage(sentiment_string, ip, port, key, pw, conda):
            import paramiko
            ssh = paramiko.SSHClient()
            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
            ssh.connect(ip, username='root', port=port, key_filename=f'/var/data/{key}_key',password=pw)

            stdin, stdout, stderr = ssh.exec_command(f'cd /opt/ml/final/model && conda activate {conda} && python riffusion_pipeline_test.py --sentiment_string "{sentiment_string}"')
            ret = stdout.readlines()
            stdin.close()
            ssh.close()

            return ret

        def _serialize_str(str_value: str) -> str:
            if not isinstance(str_value, str):
                raise TypeError('Value "{}" has type "{}" instead of str.'.format(
                    str(str_value), str(type(str_value))))
            return str_value

        import argparse
        _parser = argparse.ArgumentParser(prog='Second stage', description='')
        _parser.add_argument("--sentiment-string", dest="sentiment_string", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--ip", dest="ip", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--port", dest="port", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--key", dest="key", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--pw", dest="pw", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--conda", dest="conda", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
        _parsed_args = vars(_parser.parse_args())
        _output_files = _parsed_args.pop("_output_paths", [])

        _outputs = second_stage(**_parsed_args)

        _outputs = [_outputs]

        _output_serializers = [
            _serialize_str,

        ]

        import os
        for idx, output_file in enumerate(_output_files):
            try:
                os.makedirs(os.path.dirname(output_file))
            except OSError:
                pass
            with open(output_file, 'w') as f:
                f.write(_output_serializers[idx](_outputs[idx]))
      image: python:3.7
      volumeMounts:
      - {mountPath: var/data, name: pipeline}
    inputs:
      parameters:
      - {name: first-stage-Output}
      - {name: loop-item-param-1-subvar-conda}
      - {name: loop-item-param-1-subvar-ip}
      - {name: loop-item-param-1-subvar-key}
      - {name: loop-item-param-1-subvar-port}
      - {name: loop-item-param-1-subvar-pw}
    outputs:
      artifacts:
      - {name: second-stage-Output, path: /tmp/outputs/Output/data}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.18
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": ["--sentiment-string", {"inputValue": "sentiment_string"}, "--ip",
          {"inputValue": "ip"}, "--port", {"inputValue": "port"}, "--key", {"inputValue":
          "key"}, "--pw", {"inputValue": "pw"}, "--conda", {"inputValue": "conda"},
          "----output-paths", {"outputPath": "Output"}], "command": ["sh", "-c", "(PIP_DISABLE_PIP_VERSION_CHECK=1
          python3 -m pip install --quiet --no-warn-script-location ''paramiko==3.0.0''
          || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
          ''paramiko==3.0.0'' --user) && \"$0\" \"$@\"", "sh", "-ec", "program_path=$(mktemp)\nprintf
          \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
          "def second_stage(sentiment_string, ip, port, key, pw, conda):\n    import
          paramiko\n    ssh = paramiko.SSHClient()\n    ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n    ssh.connect(ip,
          username=''root'', port=port, key_filename=f''/var/data/{key}_key'',password=pw)\n\n    stdin,
          stdout, stderr = ssh.exec_command(f''cd /opt/ml/final/model && conda activate
          {conda} && python riffusion_pipeline_test.py --sentiment_string \"{sentiment_string}\"'')\n    ret
          = stdout.readlines()\n    stdin.close()\n    ssh.close()\n\n    return ret\n\ndef
          _serialize_str(str_value: str) -> str:\n    if not isinstance(str_value,
          str):\n        raise TypeError(''Value \"{}\" has type \"{}\" instead of
          str.''.format(\n            str(str_value), str(type(str_value))))\n    return
          str_value\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Second
          stage'', description='''')\n_parser.add_argument(\"--sentiment-string\",
          dest=\"sentiment_string\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--ip\",
          dest=\"ip\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--port\",
          dest=\"port\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--key\",
          dest=\"key\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--pw\",
          dest=\"pw\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--conda\",
          dest=\"conda\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\",
          dest=\"_output_paths\", type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files
          = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = second_stage(**_parsed_args)\n\n_outputs
          = [_outputs]\n\n_output_serializers = [\n    _serialize_str,\n\n]\n\nimport
          os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except
          OSError:\n        pass\n    with open(output_file, ''w'') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"],
          "image": "python:3.7"}}, "inputs": [{"name": "sentiment_string", "type":
          "String"}, {"name": "ip", "type": "String"}, {"name": "port", "type": "String"},
          {"name": "key", "type": "String"}, {"name": "pw", "type": "String"}, {"name":
          "conda", "type": "String"}], "name": "Second stage", "outputs": [{"name":
          "Output", "type": "String"}]}', pipelines.kubeflow.org/component_ref: '{}',
        pipelines.kubeflow.org/arguments.parameters: '{"conda": "{{inputs.parameters.loop-item-param-1-subvar-conda}}",
          "ip": "{{inputs.parameters.loop-item-param-1-subvar-ip}}", "key": "{{inputs.parameters.loop-item-param-1-subvar-key}}",
          "port": "{{inputs.parameters.loop-item-param-1-subvar-port}}", "pw": "{{inputs.parameters.loop-item-param-1-subvar-pw}}",
          "sentiment_string": "{{inputs.parameters.first-stage-Output}}"}'}
    volumes:
    - name: pipeline
      persistentVolumeClaim: {claimName: kfpvc}
  - name: test-pipeline
    dag:
      tasks:
      - {name: first-stage, template: first-stage}
      - name: for-loop-2
        template: for-loop-2
        dependencies: [first-stage]
        arguments:
          parameters:
          - {name: first-stage-Output, value: '{{tasks.first-stage.outputs.parameters.first-stage-Output}}'}
          - {name: loop-item-param-1-subvar-conda, value: '{{item.conda}}'}
          - {name: loop-item-param-1-subvar-ip, value: '{{item.ip}}'}
          - {name: loop-item-param-1-subvar-key, value: '{{item.key}}'}
          - {name: loop-item-param-1-subvar-port, value: '{{item.port}}'}
          - {name: loop-item-param-1-subvar-pw, value: '{{item.pw}}'}
        withItems:
        - {ip: 118.67.133.154, port: '2240', key: gw, pw: '0000', conda: gw}
  arguments:
    parameters: []
  serviceAccountName: pipeline-runner
